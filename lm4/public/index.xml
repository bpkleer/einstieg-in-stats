<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lernmodul 4 on WBT Statistik für die Sozialwissenschaften</title>
    <link>https://lehre.bpkleer.de/stats101/LM4/</link>
    <description>Recent content in Lernmodul 4 on WBT Statistik für die Sozialwissenschaften</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language><atom:link href="https://lehre.bpkleer.de/stats101/LM4/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Einführung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-a/</guid>
      <description>Die Ergebnisse der Korrelationsberechnungen können wir bisher nur auf die Stichprobe beziehen.
Wir wissen also in unserem Beispiel der Pearson-Korrelation, dass die die Präferenz für die CDU mit dem Alter einer Person positiv korreliert (\(r=0.97\)). Es handelt sich hierbei um eine sehr starke (fast perfekte) lineare Korrelation.
Nun soll aber in den Sozialwissenschaften nicht nur eine Aussage über eine (Zufalls-)Stichprobe getroffen werden, sondern die Aussage soll auf die Grundgesamtheit übertragen werden.</description>
    </item>
    
    <item>
      <title>Testsituationen</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-b/</guid>
      <description>Nehmen wir folgendes Beispiel zur Formulierung einer Null- und Alternativhypothese: Wir möchten testen, ob das mittlere Einkommen von Männern in einer Stichprobe größer als 2300 Euro ist. Zur Erinnerung der Erwartungswert wird immer mit \(\mu\) angegeben.
Diese Aussage formulieren wir in einer Alternativhypothese, die wie folgt lautet: \(H_A: \mu &amp;gt; 2300\)
In der Nullhypothese nehmen wir an, dass die vermutete Beobachtung nicht zutrifft. Aus unserer getroffenen Alternativhypothese ergibt sich die Nullhypothese: \(H_0: \mu ≤ 2300\)</description>
    </item>
    
    <item>
      <title>Irrtumswahrscheinlichkeit</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-c/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-c/</guid>
      <description>Um einen Hypothesentest bewerten zu können, wird eine Irrtumswahrscheinlichkeit (\(\alpha\)) angegeben, auf die der Test signifikant ist oder nicht. Um dies zu verstehen, müssen wir uns nochmals kurz verdeutlichen, welche Testsituationen auftreten können. Anhand der Vierfelder-Tabelle sind die Testsituationen dargestellt:
Fehler 1. Art und Fehler 2. Art Es gibt zwei Situationen, in denen wir korrekte Entscheidungen treffen. Wenn wir uns für die Nullhypothese entscheiden und diese auch tatsächlich korrekt ist und wenn wir uns für die Alternativhypothese entscheiden und diese auch tatsächlich korrekt ist.</description>
    </item>
    
    <item>
      <title>Vertrauenswahrscheinlichkeit</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-d/</guid>
      <description>Die Vertrauenswahrscheinlichkeit (\(p = 1 − \alpha\)) gibt die Wahrscheinlichkeit an, dass das Intervall den wahren Wert enthält. Sollte der Wert also innerhalb dieses Intervalls liegen, muss die Nullhypothese beibehalten werden und die Alternativhypothese muss verworfen werden.
Zum besseren Verständnis hier eine grafische Darstellung eines ungerichteten (zweiseitigen) Hypothesentests:
Hypothesentest zweiseitig Zur Erinnerung: Die Fläche unterhalb des Grafens stellt die Wahrscheinlichkeit dar. Der blaue Bereich ist der Vertrauensbereich. Sollte die Prüfgröße innerhalb dieses Bereichs liegen, wird die Nullhypothese beibehalten.</description>
    </item>
    
    <item>
      <title>Anwendung Korrelation</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-e/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/page-1-e/</guid>
      <description>Auch bei Korrelationen testet man die Signifikanz. Es wird also geprüft, ob der Zusammenhang in der Grundgesamtheit auch wahrscheinlich ist. In unserem vorherigen Teil haben wir die Ergebnisse noch nicht auf Signifikanz geprüft. Daher werden wir dies nun im Beispiel berechnen und durchführen.
Zur Erinnerung unser Beispiel aus der Berechnung der Pearson-Korrelation: Wir haben eine Stichprobe mit \(5\) Fällen, die jeweils das Alter und die Präferenz zur Partei CDU angegeben haben.</description>
    </item>
    
    <item>
      <title>Konfidenzintervall</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-a/</guid>
      <description>Ein Konfidenzintervall bezeichnet in den Sozialwissenschaften ein Intervall, in dem ein erwarteter Wert \(\mu\) sehr wahrscheinlich liegt. Wie wir aus der Normalverteilung wissen, bildet die Fläche unterhalb des Graphen die Wahrscheinlichkeit ab. Innerhalb dieser Flächen testen Hypothesentests, ob der angegebene Wert in diesem Intervall liegt. Für die Sozialwissenschaften hat das Intervall von [\(\mu−1.96\sigma,\mu + 1.96\sigma\)] hohe Relevanz. Dies ist das sogenannte 95%-Konfidenzintervall, da genau \(95\%\) der Fälle in diesem Intervall liegen.</description>
    </item>
    
    <item>
      <title>z-Verteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-b/</guid>
      <description>Nutzt man die \(z\)-Verteilung muss die Standardabweichung der Grundgesamtheit (\(\sigma_x\)) bekannt sein, oder durch die Stichprobe geschätzt werden. Das Intervall berechnet sich wie folgt:
\(\bar{x} \pm z_{1-\frac{\alpha}{2}} \ast {\sigma_{\bar{x}}}\)
Obergrenze Intervall:
\(x_U = \bar{x} - z_{1-\frac{\alpha}{2}} \ast {\sigma_{\bar{x}}}\)
Untergrenze Intervall:
\(x_O = \bar{x} + z_{1-\frac{\alpha}{2}} \ast {\sigma_{\bar{x}}}\)
Zur Erinnerung: Der Standardfehler des Mittelwertes (Stichprobenfehler) wird wie folgt aus der Varianz der Grundgesamtheit berechnet.
\(\sigma_{\bar{x}} = \sqrt{ \frac{\sigma^2_{x} } {n} } = \frac{ \sigma_{x}} { \sqrt{n}}\)</description>
    </item>
    
    <item>
      <title>t-Verteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-c/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-c/</guid>
      <description>Bei Stichproben mit kleinem \(n\) und unbekannter Varianz in der Grundgesamtheit (\(\sigma_x\)) empfiehlt es sich statt der \(z\)-Verteilung die \(t\)-Verteilung für die Berechnung eines Konfidenzintervalls zu nutzen.
Bei der t-Verteilung ist abhängig von den Freiheitsgraden (\(\nu\)). Freiheitsgrade geben an, wie viele Werte in einem statistischen Ausdruck frei variieren können. In der \(t\)-Verteilung berechnen sich die Freiheitsgrade wie folgt: \(\nu = n-1\).
Neben den Freiheitsgraden muss zum Bestimmen des \(t\)-Wertes auch noch die Irrtumswahrscheinlichkeit (\(\alpha\)) festgelegt werden.</description>
    </item>
    
    <item>
      <title>Beispiele</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter1/subchapter1/page-1-1-d/</guid>
      <description>Im Folgenden werden zwei Beispiele berechnet, die auch in dem Lernvideo nochmals erklärt werden.
bekanntes \(\sigma_x\) Wir haben eine Umfrage mit \(2064\) Befragten (\(n=2064\)) mit einem Durchschnittsalter von \(42.7\) Jahren (\(\bar{x}_{Alter} = 42.7\)) und einer Standardabweichung in der Grundgesamtheit von \(11.2\) Jahren (\(\sigma_{Alter} = 11.2\)). Wir wollen das \(90\%\)-Konfidenzintervall berechnen.
\(n = 2064\)
\(\bar{x}_{Alter} = 42.7\)
\(\sigma_{Alter} = 11.2\)
\(z_{0.95} = 1.645\)
Geschätzter Standardfehler der Grundgesamtheit ist daher:
\(\hat{\sigma}_\bar{x} = \frac{\sigma_x}{\sqrt{n}} = \frac{11.</description>
    </item>
    
    <item>
      <title>Einführung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/page-2-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/page-2-a/</guid>
      <description>Mit Mittelwertvergleichen werden also Zusammenhänge zwischen nominalen (Gruppenvariable, im Beispiel Geschlecht) und metrischen Variablen (im Beispiel Einkommen) getestet.
Für den Mittelwertvergleich gibt es mehrere Verfahren, die in Abhängigkeit der Gruppenanzahl der nominalen Variable und in Abhängigkeit der Stichprobe angewandt werden. Für einen Mittelwertvergleich zwischen zwei Gruppen wird der sogenannte t-test (Mittelwertvergleich) genutzt und für eine Untersuchung von mehr als zwei Gruppen der sogenannte F-Test (Varianzanalyse).
Bei beiden genannten Verfahren wird nochmals unterschieden, ob die Stichproben abhängig oder unabhängig voneinander sind.</description>
    </item>
    
    <item>
      <title>Formulierung t-Test</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-a/</guid>
      <description>Als Beispiel für die Berechnung eines ungepaarten \(t\)-tests nehmen wir folgende Frage auf: Weisen Frauen und Männer einen unterschiedlichen Mittelwert bei der wöchentlichen Arbeitszeit auf? Falls ja, sind diese Unterschiede statistisch signifikant?
Der \(t\)-test ist ein Hypothesentest. In der Nullhypothese wird geprüft, dass es keine Unterschiede zwischen den Mittelwerten gibt und in der Alternativhypothese, dass es einen Unterschied gibt. Diese Alternativhypothese kann gerichtet (einseitig) wie ungerichtet (zweiseitig) geprüft werden.</description>
    </item>
    
    <item>
      <title>Beispiel gleiche Varianzen</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-b/</guid>
      <description>Kommen wir nun zu einem Rechenbeispiel des zweiseitigen t-Tests für unabhängige Stichproben mit gleichen Varianzen. Als Beispiel übernehmen wir die Fragestellung, die wir eingangs als Beispiel benannt haben: Weisen Frauen und Männer einen unterschiedlichen Mittelwert bei der wöchentlichen Arbeitszeit auf? Falls ja, sind diese Unterschiede statistisch signifikant?
Aus einem Survey haben wir folgende Daten:
Frauen: \(\bar{x}_1 = 34.14084, s_1 = 10.89673, n_1 = 884\)
Männer: \(\bar{x}_2 = 43.64809, s_2 = 9.</description>
    </item>
    
    <item>
      <title>Beispiel ungleiche Varianzen</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-c/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-c/</guid>
      <description>Nun wollen wir ein Beispiel für einen \(t\)-Test mit unabhängigen Stichproben, aber ungleichen Varianzen berechnen. Dieser Test wird auch Welch-Test oder \(t\)-Test mit Welch-Korrektur genannt. Aus einer weiteren Stichprobe haben wir folgende Werte, wobei Varianzgleichheit zwischen den Gruppen nicht gegeben ist.
Frauen: \(\bar{x}_1 = 34.14084, s_1 = 5.89673, n_1 = 884\)
Männer: \(\bar{x}_2 = 43.64809, s_2 = 11.541511, n_2 = 1023\)
Der empirische \(t\)-Wert berechnet sich wie folgt:
\(t_{emp} = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}}}\)</description>
    </item>
    
    <item>
      <title>Beispiel Veröffentlichung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter1/page-2-1-d/</guid>
      <description>In Veröffentlichungen sind die Ergebnisse oft verkürzt dargestellt. Hier kommen wir auf ein ähnliches Beispiel wie auf der vorherigen Seite zurück, allerdings mit Daten aus dem ALLBUS 2008. Bei einem Mittelwertvergleich werden immer die Mittelwerte (\(\bar{x}\)) beider Gruppen sowie die Differenz angegeben.
Mittelwertvergleich (Wochenarbeitsstunden nach Geschlecht) Anhand dieser Ausgabe erkennt man, dass sich die mittlere wöchentliche Arbeitszeit zwischen den beiden Gruppen (Männer und Frauen) um ca. \(9\) Stunden unterscheidet. Dies gilt in dem Maße nur für die Stichprobe.</description>
    </item>
    
    <item>
      <title>Berechnung mit Rohwerten</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter2/page-2-2-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter2/page-2-2-a/</guid>
      <description>Dazu nehmen wir folgendes Beispiel an: In einem Landtag wurde ein neues Bildungsprogramm für Schulen initiiert, dass u.a. das politische Wissen der teilnehmenden Schüler:innen steigern soll. Dazu wurde vor der Teilnahme und nach der Teilnahme jeweils das politische Wissen gemessen. Von jeder Schüler:in liegen also zwei Messwerte vor: einmal das politische Wissen vor der Teilnahme (\(x_1\)) und einmal das politische Wissen nach der Teilnahme (\(x_2\)).
Wir haben folgende Messwerte für 5 fiktive Schüler:innen: \(x_1\) ist der Messwert vor der Teilnahme, \(x_2\) der Messwert nach der Teilnahme und \(d\) die Differenz zwischen \(x_1\) und \(x_2\).</description>
    </item>
    
    <item>
      <title>Angegebene Differenzwerte</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter2/page-2-2-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter2/subchapter2/page-2-2-b/</guid>
      <description>Man kann den \(t\)-Test für abhängige Stichproben auch berechnen, wenn die Werte des Mittelwerts der Differenzen der gepaarten Mittelwerte (\(\bar{x}_d\)) sowie die Standardabweichung der Differenzen der gepaarten Mittelwerte (\(\hat{\sigma}_d\)) angegeben sind. Wir nehmen das Beispiel von oben, gehen aber nun von folgenden Werten für eine Stichprobe mit \(1.000\) Schüler:innen aus.
\(\bar{x}_d = -3.7\)
\(\hat{\sigma}_d = 1.3\)
\(n = 1000\)
Hier müssen nun nur die Rechenschritte aus dem vorherigen Beispiel ab Punkt 3 berechnet werden:</description>
    </item>
    
    <item>
      <title>Einführung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-a/</guid>
      <description>Im ersten Schritt werden nun die mathematischen Grundlagen des Verfahrens der linearen Regression am Beispiel einer bivariaten linearen Regression vorgestellt. Aufbauend darauf werden die Grundlagen auf eine multivariate lineare Regression übertragen und die Interpretation der wichtigsten Kennzahlen vorgestellt. Abschließend wird zum besseren Verständnis ein Praxisbeispiel aktueller Forschung der empirischen Demokratieforschung dargestellt.
Die Regressionsanalyse ist eine statistische Methode, um die Beziehungsstruktur zwischen mehreren Variablen zu untersuchen. Dabei findet eine Informationsreduktion statt, so dass die Untersuchung auf wenige Kennzahlen beschränkt werden kann.</description>
    </item>
    
    <item>
      <title>Lineare Gleichung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-b/</guid>
      <description>Die Grundannahme einer linearen Regression ist die lineare Darstellung, in der die abhängige Variable \(Y\) über eine Linearkombination mit der unabhängigen Variable \(X\) dargestellt wird:
\(y = \beta_0 + \beta_1 \ast x\)
\(\beta_0\) stellt die Konstante (engl. intercept) dar, also den Schnittpunkt mit der \(y\)-Achse. In manchen Veröffentlichungen wird hierfür auch ein kleines \(a\) oder \(\alpha\) verwendet. \(\beta_1\) ist die Steigung der Geraden, in diesem Fall die Steigung der abhängigen Variable \(y\) durch die unabhängige Variable \(x\) (englt.</description>
    </item>
    
    <item>
      <title>Bivariate Regression</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-c/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-c/</guid>
      <description>Bei der Berechnung einer linearen Regression in den Sozialwissenschaften lässt sich das Regressionsmodell nur mit einer Anpassung als lineare Darstellung durchführen. Dies liegt daran, dass keine abhängige Variable perfekt durch eine oder mehrere unabhängige Variable(n) darstellbar ist. In der Modellannahme wird deshalb davon ausgegangen, dass es einen nicht-erklärbaren Anteil gibt, der mit der Störvariable \(\varepsilon\) (manchmal auch \(U\)) angegeben wird. In den Sozialwissenschaften ergibt sich diese Störvariable aus der Forschungslogik heraus: Wir können in den Sozialwissenschaften niemals alle Variablen, die auf etwas wirken, berücksichtigen, da ein soziales Ereignis stets umfassend ist.</description>
    </item>
    
    <item>
      <title>Beispiel</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-d/</guid>
      <description>Kommen wir nun zu einem eingängigeren Beispiel: Die folgenden Daten sind fiktiv generiert, damit diese das Verfahren gut simulieren können. Wir möchten eine bivariate lineare Regression berechnen, in der die Zufriedenheit mit der Demokratie (satdem) durch die Zufriedenheit mit der ökonomischen Leistung (sateco) berechnet wird. Wir prüfen also, ob und inwieweit die Zufriedenheit mit der ökonomischen Leistung die Zufriedenheit mit der Demokratie beeinflusst.
Die Formel unseres Modells lautet daher: \(satdem_i= \beta_0 + \beta_1 \ast sateco_i + e_i\), wobei \(i=1,…,n\).</description>
    </item>
    
    <item>
      <title>Schätzverfahren</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-e/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-e/</guid>
      <description>In diesem Lernvideo werden die relevanten Teile der Regressionsberechnung an einem weiteren Beispiel vereinfacht dargestellt und das mathematische Vorgehen der Berechnung der besten Regressionsgeraden kurz erläutert. Weitergehende Ausführungen sind unterhalb des Lernvideos im Text zu finden.
Kommen wir zurück zur Modellschätzung. Die Gleichung einer Modellschätzung lautet: \(Y = \beta_0 + \beta_1 \ast X + e\) Mit \(Y = (y_1, y_2, ..., y_n), X = (x_1, x_2, ..., x_n)\) und \(e=(e_1, e_2, .</description>
    </item>
    
    <item>
      <title>Multivariate lineare Regression</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-f/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/page-3-f/</guid>
      <description>Nun erweitern wir die Annahmen auf mehrere unabhängige Variablen. Mit der Regression als multivariate Analyse können Einflüsse möglicher Drittvariablen kontrolliert werden und es wird Aufschluss über die Abhängigkeitsstrukturen zwischen mehreren Variablen gegeben. Die Regression ist daher ein strukturprüfendes Verfahren.
Bei der multivariaten Regression betrachten wir nicht mehr nur eine unabhängige Variable, sondern beziehen mehrere unabhängige Variablen in das Modell hinein. Der Einbezug von unabhängigen Variablen findet stets theoriegeleitet statt. Die Modellformulierung der multivariaten linearen Regression ändert sich daher auf folgende:</description>
    </item>
    
    <item>
      <title>Bestimmtheitsmaß</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-a/</guid>
      <description>Um zu messen, wie aussagekräftig die Regression ist, wird über eine Varianzzerlegung das Bestimmtheitsmaß \(R^2\) bestimmt. Vereinfacht dargestellt beschreibt \(R^2\) den Anteil der erklärten Varianz am Gesamtanteil.
Umgangssprachlich könnte man sagen, dass \(R^2\) angibt, wie viel die unabhängigen Variablen (an der Varianz) der abhängigen Variable erklären. Es ist somit ein Maß der Güte des Modells. Das Ziel ist es, ein Modell zu finden, dass möglichst einen großen Anteil der Varianz einer abhängigen Variable erklären kann (also ein hohes \(R^2\) aufweist).</description>
    </item>
    
    <item>
      <title>F-Test</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-b/</guid>
      <description>Neben \(R^2\) muss ein weiteres Modellmaß interpretiert werden: der \(F\)-Test des Bestimmtheitsmaßes: Der \(F\)-Test ist ein Hypothesentest und prüft in der Nullhypothese, dass das Bestimmtheitsmaß \(R^2\) \(=0\) ist, also dass das zugrunde gelegte Modell keine Varianz der abhängigen Variable erklärt. Trifft diese Nullhypothese zu, muss das Modell verworfen werden. In Veröffentlichungen findet man daher nur Modelle, die diesen \(F\)-Test „bestanden haben“, also in denen mindestens ein Regressionskoeffizient einer unabhängigen Variable von \(0\) abweicht.</description>
    </item>
    
    <item>
      <title>Regressionskoeffizienten</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-c/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-c/</guid>
      <description>In Veröffentlichungen von Regressionsmodellen finden Sie neben der Angabe des Bestimmtheitsmaßes \(R^2\) auch immer die Angabe der einzelnen Regressionskoeffizienten und deren Signifikanz. Denn in den meisten Regressionsmodellen geht es nicht nur um die Erklärungskraft eines Modells, sondern auch darum, wie einzelne Faktoren auf die abhängige Variable wirken. Daher ist die Angabe und die Interpretation der Regressionskoeffizienten wichtig.
In der Abbildung sehen wir wieder einen Auszug der Beispielregression: Im Computerprogramm SPSS wird dieser als Koeffizientenblock bezeichnet, in R finden wir diese auch wie zuvor in der normalen Modell-Ausgabe.</description>
    </item>
    
    <item>
      <title>Lernvideo</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter1/page-3-1-d/</guid>
      <description>In diesem Lernvideo werden die drei Schritte nochmals dargestellt:</description>
    </item>
    
    <item>
      <title>Beispiel 1</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter2/page-3-2-a/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter2/page-3-2-a/</guid>
      <description>Nun möchten wir das Bildungslevel der Befragten in die Regressionsrechnung einfügen. Insgesamt hat diese Variable drei Ausprägungen: \((1)\) Haupt-/Realschule, \((2)\) Abitur und \((3)\) mind. BA-Abschluss. Der Bildungslevel beschreibt die höchste formale Bildungsqualifikation.
Ein Statistikprogramm kann ausschließlich mit Zahlen operieren. Warum wir die Variable nicht wie eine metrische Variable einfügen können, erklärt folgendes Problem: Bei metrischen Variablen können wir die Steigerung um eine Einheit interpretieren, da die Abstände eindeutig sind. Bei einer Variable wie dem Bildungslevel können wir dies nicht.</description>
    </item>
    
    <item>
      <title>Beispiel 2</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter2/page-3-2-b/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/chapter3/subchapter2/page-3-2-b/</guid>
      <description>In den zwei Lernvideos wird zum einen gezeigt wie Dummy-Variablen grafisch zu interpretieren sind und wie Dummy-Variablen gebildet werden.
Nehmen wir ein weiteres Beispiel für dummykodierte Variablen mit ordinalen Skalenniveau: Wir möchten testen, welchen Einfluss - neben den bereits genutzten Variable (Alter, Arbeitszeit, Geschlecht) - der Schulabschluss auf das Einkommen einer Person hat. Der Schulabschluss ist in unserem Beispiel mit drei Merkmalsausprägungen kodiert:
\(1:Hauptschule\)
\(2:Realschule\)
\(3:(Fach−)Abitur\)
Welche Ausprägung die Referenzkategorie ist, liegt in der Entscheidung der Forscher:in.</description>
    </item>
    
    <item>
      <title>abhängige Stichprobe</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/abhaengigestichprobe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/abhaengigestichprobe/</guid>
      <description>liegt vor, wenn jedem Wert der einen Stichprobe eindeutig und sinnvoll ein Wert der anderen Stichprobe zugeordnet werden kann (z.B. Mutter und Kind; Messung eines Individuums zu zwei Zeitpunkten)</description>
    </item>
    
    <item>
      <title>abhängige Variable</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/abhaengigevariable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/abhaengigevariable/</guid>
      <description>Die abhängige Variable (Kurzform: aV) ist die Variable, die beeinflusst wird (Wirkung). In Gleichungen wird diese mit einem \(Y\) gekennzeichnet. Sie wird auch als Zielvariable oder zu erklärende Variable bezeichnet.</description>
    </item>
    
    <item>
      <title>Alternativhypothese</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/alternativhypothese/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/alternativhypothese/</guid>
      <description>Ungetestete Hypothese in einem Hypothesentest; wird angenommen, wenn Nullhypothese verworfen wird; die Alternativhypothese nimmt in den Sozialwissenschaften inhaltlich die theoretische Vermutung der Forschenden ein.</description>
    </item>
    
    <item>
      <title>Bestimmtheitsmaß</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/bestimmtheitsmass/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/bestimmtheitsmass/</guid>
      <description>\(R^2\); Gütemaß einer Modellregression; nimmt Werte zwischen 0 und 1 an; je höher \(R^2\), desto mehr erklären die unabhängigen Variablen die Varianz der abhängigen; umgangssprachlich gibt \(R^2\) die Prozente an, die das Regressionsmodell erklärt; Beispiel \(R^2= 0,54\) \(\Rightarrow\) erklärt 54 % der Varianz der abhängigen Variable.</description>
    </item>
    
    <item>
      <title>bewusste Auswahl</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/bewussteauswahl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/bewussteauswahl/</guid>
      <description>Verfahren der nicht-wahrscheinlichkeitsbasierten Auswahl einer Stichprobe; gezielte Auswahl („typischer Fall“; „ausschlaggebender Fall“) ; oft genutzt in explorativen Studien; Auswahl ist kriteriengeleitet.</description>
    </item>
    
    <item>
      <title>bivariat</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/bivariat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/bivariat/</guid>
      <description>betrachtet man die gemeinsame Verteilung zweier Merkmale bzw. Variablen, spricht man von einer bivariaten Analyse.</description>
    </item>
    
    <item>
      <title>Credits</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/credits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/credits/</guid>
      <description>Contributors Web-Based-Training (since v1.0) @B. Philipp Kleer 19 commits Contributors to hugo-learner-theme Thanks to them for making Open Source Software a better place!
@matcornic 158 commits @matalo33 48 commits @coliff 19 commits @lierdakil 16 commits @mdavids 10 commits @ozobi 5 commits @Xipas 5 commits @Alan-Cha 4 commits @pdelaby 4 commits @helfper 4 commits @Chris-Greaves 3 commits @mreithub 3 commits @massimeddu 3 commits @LinuxSuRen 3 commits @dptelecom 3 commits @willwade 3 commits @diemol 2 commits @denisvm 2 commits @hucste 2 commits @ImgBotApp 2 commits @jamesbooker 2 commits @jice-lavocat 2 commits @wikijm 2 commits @lfalin 2 commits @JianLoong 2 commits @armsnyder 1 commits @afilini 1 commits @MrAkaki 1 commits @AmirLavasani 1 commits @afs2015 1 commits @arifpedia 1 commits @berryp 1 commits @MrMoio 1 commits @ChrisLasar 1 commits @DCsunset 1 commits @IEvangelist 1 commits @fritzmg 1 commits @bogaertg 1 commits @geoffreybauduin 1 commits @giuliov 1 commits @haitch 1 commits @zeegin 1 commits @RealOrangeOne 1 commits @jared-stehler 1 commits @JohnBlood 1 commits @JohnAllen2tgt 1 commits @kamilchm 1 commits @gwleclerc 1 commits @lloydbenson 1 commits @massimocireddu 1 commits @sykesm 1 commits @nvasudevan 1 commits @nnja 1 commits @owulveryck 1 commits @654wak654 1 commits @PierreAdam 1 commits @qiwenmin 1 commits @ripienaar 1 commits @stou 1 commits @razonyang 1 commits @HontoNoRoger 1 commits @pocc 1 commits @EnigmaCurry 1 commits @taiidani 1 commits @exKAZUu 1 commits @Oddly 1 commits @sandrogauci 1 commits @shelane 1 commits @mbbx6spp 1 commits @swenzel 1 commits @tedyoung 1 commits @Thiht 1 commits @editicalu 1 commits @fossabot 1 commits @kamar535 1 commits @mtbt03 1 commits @ngocbichdao 1 commits @nonumeros 1 commits @pgorod 1 commits @proelbtn 1 commits And a special thanks to vjeantet for his work on docdock, a fork of hugo-theme-learn.</description>
    </item>
    
    <item>
      <title>dichotom</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/dichotom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/dichotom/</guid>
      <description>Eine Variable ist dichotom, wenn sie nur zwei Merkmalsausprägungen hat (Bsp. Wahlteilnahme: ja/nein).</description>
    </item>
    
    <item>
      <title>dummykodierte Variable</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/dummykodiertevariable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/dummykodiertevariable/</guid>
      <description>Möglichkeit der Inklusion von ordinalen und nominalen Variablen als unabhängige Variablen im linearen Regressionsmodell; bei Interpretation muss Referenzkategorie festgelegt werden;</description>
    </item>
    
    <item>
      <title>Einseitiger Test</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/einseitigertest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/einseitigertest/</guid>
      <description>auch gerichteter T. genannt; es wird eine Richtung über die Abweichung eines angenommenen Wertes festgelegt; Ablehnungsbereich einer Hypothese ist auf eine Seite festgelegt</description>
    </item>
    
    <item>
      <title>Erwartungswert</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/erwartungswert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/erwartungswert/</guid>
      <description>Grundbegriff der Wahrscheinlichkeitsrechnung; griechischer Buchstabe \(\mu\); Erwartungswert ist der Wert, die die untersuchte Variable im Mittelwert in der Population annimmt (in Abhängigkeit der Verteilungsform der Variablen)</description>
    </item>
    
    <item>
      <title>F-Verteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/fverteilung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/fverteilung/</guid>
      <description>Fisher-Verteilung; Verteilungsform der Quotienten zweier \(\chi^2\)-verteilter Zufallsvariablen dividiert durch die Anzahl der Freiheitsgerade; wichtige Verteilung für die Varianzanalyse (inferenzstatistische Verfahren)</description>
    </item>
    
    <item>
      <title>Grundgesamtheit</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/grundgesamtheit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/grundgesamtheit/</guid>
      <description>auch Zielpopulation oder angestrebte Grundgesamtheit; Menge aller Einheiten, über die wir eine Aussage treffen wollen.</description>
    </item>
    
    <item>
      <title>Homoskedastizität</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/homoskedastizitaet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/homoskedastizitaet/</guid>
      <description>Homoskedastizität ist eine Annahme der linearen Regression. Dies setzt somit voraus, dass die Varianzen der Residuen an allen Prädiktorwerte für die abhängige Variable gleich sein müssen. Die Streuung dieser darf mit zunehmenden oder abnehmenden Werten nicht größer/kleiner werden. Sollte keine Homoskedastizität vorhanden sind, sind die Schätzer nicht zuverlässig. Das heißt, dass die Standardabweichung, das Konfidenzintervall und dadurch die Teststatistiken auf Signifikanz nicht interpretierbar sind.</description>
    </item>
    
    <item>
      <title>Inferenzstatistik</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/inferenzstatistik/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/inferenzstatistik/</guid>
      <description>Mithilfe der Inferenzstatistik können Rückschlüsse aus einer zufallsbasierten Stichprobe auf die Grundgesamtheit übertragen werden. Hierbei werden i.d.R. Hypothesen- bzw. Signifikanztests durchgeführt.</description>
    </item>
    
    <item>
      <title>Irrtumswahrscheinlichkeit</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/irrtumswahrscheinlichkeit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/irrtumswahrscheinlichkeit/</guid>
      <description>Auch Fehler 1. Art oder \(\alpha\)-Fehler; gibt an, in wie vielen Fällen die Entscheidung auf die Alternativhypothese fällt, obwohl die Nullhypothese richtig ist.</description>
    </item>
    
    <item>
      <title>kategoriales Skalenniveau</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/kategorialesskalenniveau/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/kategorialesskalenniveau/</guid>
      <description>umfasst nominale wie ordinale Skalenniveaus.</description>
    </item>
    
    <item>
      <title>Kausalität</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/kausalitaet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/kausalitaet/</guid>
      <description>Das Ziel insbesondere hypothesen- und theorie-prüfender Untersuchungen ist die Bestimmung von Ursache-Wirkungs-Beziehungen. Diese Ursache-Wirkungs-Beziehung wird auch als Kausalität bezeichnet.
Eine Kausalaussage ist „eine Aussage, in der behauptet wird, dass bestimmte Phänomene Ursachen für andere Phänomene sind“ (Opp 2010). Die Ursache (X) muss zeitlich vor der Wirkung (Y) liegen.</description>
    </item>
    
    <item>
      <title>Konfidenzintervall</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/konfidenzintervall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/konfidenzintervall/</guid>
      <description>bezeichnet in den Sozialwissenschaften ein Intervall, in dem ein erwarteter Wert μ sehr wahrscheinlich liegt; in Sozialwissenschaften gängige Intervalle: 95%-Konfidenzintervall (Wert liegt zu 95% in dem Intervall) und 99%-Konfidenzintervall (Wert liegt zu 99% in dem Intervall)</description>
    </item>
    
    <item>
      <title>Korrelation</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/korrelation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/korrelation/</guid>
      <description>beschreibt in allgemeiner Weise den Zusammenhang zwischen zwei Variablen; mithilfe des Korrelationskoeffizienten wird eine Kennzahl berechnet, die einfach interpretierbar ist.</description>
    </item>
    
    <item>
      <title>Kritischer Wert</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/kritischerwert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/kritischerwert/</guid>
      <description>Teil des Signifikanztests; Prüfgröße muss größer als der kritische Wert sein, damit der Wert als signifikant wird; wird aus Verteilungstabellen in Abhängigkeit der Irrtumswahrscheinlichkeit und der Freiheitsgrade (degree of freedoms, \(\nu\)) abgelesen.</description>
    </item>
    
    <item>
      <title>lineare Regression</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/lineareregression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/lineareregression/</guid>
      <description>multivariates Analyseverfahren; eine metrische abhängige Variable wird durch mehrere unabhängige Variablen erklärt; Die lineare Regression ist ein strukturprüfendes Modell, mit dem eine Ursachenanalyse und Wirkungsprognose möglich ist. Es lassen sich theoretisch entwickelte Hypothesen über die Beeinflussungsstruktur bestimmter Variablen auf andere Variablen prüfen.
Ursachenanalyse: Wie stark ist der Einfluss der unabhängigen Variablen auf abhängige Variable?
Wirkungsprognose: Wie verändert sich abhängige Variable bei der Veränderung der unabhängigen Variable?
Allgemeines Modell der linearen Regression: \(y_i=\beta_0 + \beta_1 ∗ x_{1,i} + .</description>
    </item>
    
    <item>
      <title>Merkmalsausprägung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/merkmalsauspraegung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/merkmalsauspraegung/</guid>
      <description>Merkmale können verschiedene Werte annehmen, die Merkmalsausprägungen genannt werden (Bsp. Augenfarbe; Merkmalsausprägungen= grün, blau, braun).</description>
    </item>
    
    <item>
      <title>metrisches Skalenniveau</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/metrischesskalenniveau/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/metrischesskalenniveau/</guid>
      <description>umfasst intervall- und ratio-skalierte Merkmale.</description>
    </item>
    
    <item>
      <title>Mittelwert</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/mittelwert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/mittelwert/</guid>
      <description>auch arithmetisches Mittel; Maß der zentralen Tendenz; stellt den Durchschnittswert der Verteilung dar und daher muss das Merkmal mind. intervallskaliert sein. Es werden alle erhobenen Werte aufsummiert und dann durch die Anzahl der vorhandenen Werte geteilt. Der Mittelwert wird durch Ausreißer und Extremwerte stark beeinflusst, da alle Werte gleichermaßen und ungewichtet in die Berechnung einbezogen werden.
Formel zur Berechnung: \(\bar{x}=\frac {1} {n} * \sum_{i=1} ^n x_i\)</description>
    </item>
    
    <item>
      <title>Multivariat</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/multivariat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/multivariat/</guid>
      <description>Betrachtet man die gemeinsame Verteilung von mehr als zwei Merkmalen bzw. Variablen, spricht man von einer multivariaten Analyse.</description>
    </item>
    
    <item>
      <title>Nominal-Skala</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/nominalskala/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/nominalskala/</guid>
      <description>Niedrigste Skala der vier Skalenniveaus. Zu untersuchende Objekte können lediglich hinsichtlich ihres Vorhandenseins/Nichtvorhandenseins bzw. der Gleichheit/Ungleichheit untersucht werden.
Mathematische Operatoren: \(=\) \(/\) \(≠\)
Messbare Eigenschaften: Häufigkeit
Beispiel: Wohnort, Universität, Augenfarbe.</description>
    </item>
    
    <item>
      <title>Normalverteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/normalverteilung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/normalverteilung/</guid>
      <description>auch Gauß’sche Normalverteilung; Mittelwert und Streuung beschreiben die Lage; symmetrisch, nähert sich asymptotisch der \(Y\)-Achse an; größte Häufigkeiten liegen in der Mitte, geringere Häufigkeiten rechts bzw. links von der Mitte; Median, Modus und Mittelwert nehmen in einer Normalverteilung denselben Wert an; wichtige Verteilungsform für eine Reihe quantitativer Analyseverfahren und für die Inferenzstatistik.</description>
    </item>
    
    <item>
      <title>Nullhypothese</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/nullhypothese/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/nullhypothese/</guid>
      <description>Getestete Hypothese in einem Hypothesentest; die Nullhypothese umfasst i.d.R. die Negierung der aufgestellten Alternativhypothese (der Forschungshypothese)</description>
    </item>
    
    <item>
      <title>Ordinal-Skala</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/ordinalskala/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/ordinalskala/</guid>
      <description>Zweitniedrigste Skala der vier Skalenniveaus. Die Ordinal-Skala besitzt die Eigenschaften der Nominalskala (Verlinkung) und zusätzlich können die Ausprägungen in eine bestimmte Rangfolge bringen (größer/kleiner, schlechter/besser). Mathematische Operatoren: \(= / ≠ ; &amp;lt; / &amp;gt;\) Messbare Eigenschaften: Häufigkeit, Rangordnung Beispiel: Schulabschluss</description>
    </item>
    
    <item>
      <title>Ordinary-Least-Squares-Verfahren</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/ols/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/ols/</guid>
      <description>auch OLS-Verfahren; auch kleinste-Quadrate-Verfahren genannt; Berechnungsmethode der linearen Regression; Regressionsgerade wird über Minimierung der Summe der Abweichungen der Residuen geschätzt.</description>
    </item>
    
    <item>
      <title>Pearsons r</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/pearsonsr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/pearsonsr/</guid>
      <description>Korrelationskoeffizient für metrische Variablen; Voraussetzung zur Berechnung ist Linearität und Monotonie des Zusammenhangs.</description>
    </item>
    
    <item>
      <title>polytom</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/polytom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/polytom/</guid>
      <description>Als polytom werden Variablen beschrieben, die mehr als zwei Ausprägungen besitzen. (z.B. die Augenzahl beim Wurf eines Würfels).</description>
    </item>
    
    <item>
      <title>pseudometrisch</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/pseudometrisch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/pseudometrisch/</guid>
      <description>ordinales Skalenniveau, wobei gleichwertige Abstände zwischen Ausprägungen angenommen werden; betrifft oftmals Skalen und wird angewendet bei Skalen ab 11 Ausprägungen (z.B. 0-10er Skala der Zustimmung).</description>
    </item>
    
    <item>
      <title>quantitative Sozialforschung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/quantitativesozialforschung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/quantitativesozialforschung/</guid>
      <description>Die quantitative Sozialforschung zeichnet sich durch „ein streng zielorientiertes Vorgehen aus, das die Objektivität (…) der Resultate durch möglichst weitgehende Standardisierung aller Teilschritte anstrebt und das zur Qualitätssicherung die intersubjektive Nachprüfbarkeit des gesamten Prozesses als zentrale Norm postuliert“ (Kromrey 2009: 25).
Ist das Ziel eine Generalisierung von Aussagen werden oftmals Verfahren quantitativer Sozialforschung angewendet.</description>
    </item>
    
    <item>
      <title>Referenzkategorie</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/referenzkategorie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/referenzkategorie/</guid>
      <description>Festlegen der Referenzkategorie bei Hinzufügen ordinaler/nominaler Variablen in der linearen Regression; Regressionskoeffizienten geben die Veränderung auf der abhängigen Variable im Vergleich von angegebener Kategorie zur Referenzkategorie aus</description>
    </item>
    
    <item>
      <title>Regressionskoeffizienten</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/regressionskoeffizienten/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/regressionskoeffizienten/</guid>
      <description>Einflussfaktoren einzelner unabhängiger Variable auf abhängige Variable (unter Konstanthalten der anderen unabhängigen Variablen); es wird unterschieden zwischen standardisierten und nicht-standardisierten Regressionskoeffizienten</description>
    </item>
    
    <item>
      <title>Residuum</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/residuum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/residuum/</guid>
      <description>Umfasst die Differenz von geschätzten \(y\)-Wert und beobachteten \(y\)-Wert \((\hat{y})\); Formel: \(e_i= y_i - \hat{y}_i\) ; mathematische Rechenwert in der Regression</description>
    </item>
    
    <item>
      <title>Scatterplot</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/scatterplot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/scatterplot/</guid>
      <description>auch Streudiagramm genannt; S. zwischen zwei Variablen; wird insbesondere bei Zusammenhang zwischen metrischen Variablen genutzt; wird zur Kontrolle der Linearität und Monotonie bei Pearson-Korrelation genutzt.</description>
    </item>
    
    <item>
      <title>Signifikanzniveau</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/signifikanzniveau/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/signifikanzniveau/</guid>
      <description>gibt an, wie hoch das Risiko ist einen Fehler 1. Art (\(\alpha\)-Fehler) zu begehen; auch Irrtumswahrscheinlichkeit</description>
    </item>
    
    <item>
      <title>Signifikanztest</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/signifikanztest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/signifikanztest/</guid>
      <description>auch Hypothesentest genannt; Test der Inferenzstatistik; es wird getestet, inwieweit ein Zusammenhang in der Stichprobe auch in der Grundgesamtheit wahrscheinlich ist (-&amp;gt;Inferenz); getestet wird die Nullhypothese (also das Gegenteil der Annahme muss widerlegt werden); Alternativhypothese beinhaltet theoretische Vermutung der Forscher*in; Entscheidung wird gegen Nullhypothese unter Irrtumswahrscheinlichkeit gefällt; Testgröße in Abhängigkeit der Verteilung (z.B. t-Test, F-Test oder z-Test); es wird zwischen einem einseitigen (Richtungstest) und zweiseitigen Signifikanztest (ungleich/gleich-Test) unterschieden.</description>
    </item>
    
    <item>
      <title>Skalenniveau</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/skalenniveau/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/skalenniveau/</guid>
      <description>Skalenniveaus werden zur Bestimmung der Relationen zwischen Variablen definiert. Man unterscheidet zwischen Nominal-, Ordinal-, Intervall- und Ratio-Skala.</description>
    </item>
    
    <item>
      <title>Standardabweichung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/standardabweichung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/standardabweichung/</guid>
      <description>Streuungsmaß; Angabe mit \(\sigma\); wird berechnet als Wurzel aus der Varianz (\(\sigma=\sqrt{\sigma^2}\); gibt die durchschnittliche Abweichung vom Mittelwert der Verteilung an (in der Maßeinheit der Variablen). Für die Berechnung einer Standardabweichung aus einer Stichprobe wird die Bessel-Korrektur angewendet (\(\frac{1}{n-1}\)): \(s = \sqrt{\frac{1}{n-1}*s^2}\)</description>
    </item>
    
    <item>
      <title>Stichprobe</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/stichprobe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/stichprobe/</guid>
      <description>ist ein Teil der Grundgesamtheit; da oftmals keine Vollerhebung stattfinden kann, werden Stichproben aus der Grundgesamtheit gezogen; um inferenzstatistische Verfahren anwenden zu können, müssen Stichproben zufallsbasiert gezogen werden.</description>
    </item>
    
    <item>
      <title>Stichprobenumfang</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/stichprobenumfang/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/stichprobenumfang/</guid>
      <description>Anzahl der Beobachtungseinheiten in einer Stichprobe.</description>
    </item>
    
    <item>
      <title>Störvariable</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/stoervariable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/stoervariable/</guid>
      <description>Theoretische Größe des theoretischen Regressionsmodell; in Sozialwissenschaften können nie alle notwendigen Variablen erfasst werden, daher kann nie ein perfekter Zusammenhang dargestellt werden; Störvariablen bilden den Term ϵ, der als Fehlerterm der Lineargleichung der Regression hinzugefügt wird.</description>
    </item>
    
    <item>
      <title>t-Test (Regression)</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/ttestregression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/ttestregression/</guid>
      <description>testet die Signifikanz der einzelnen Regressionskoeffizienten gegen die Nullhypothese, dass diese je 0 sind \((H_0: \beta_i=0)\); beruht auf t-Verteilung;</description>
    </item>
    
    <item>
      <title>t-Verteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/tverteilung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/tverteilung/</guid>
      <description>glockenförmige, flache Verteilung; wird für kleine Stichproben genutzt (n&amp;lt;30); kann auch bei Unwissenheit über die Standardabweichung der Grundgesamtheit genutzt werden; geht bei großen Stichproben in Normalverteilung über;</description>
    </item>
    
    <item>
      <title>unabhängige Stichprobe</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/unabhaengigestichprobe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/unabhaengigestichprobe/</guid>
      <description>liegt vor, wenn keine Zuordnung zwischen den Fällen möglich ist (z.B. Aufteilung eines Datensatzes nach Geschlecht, eine Stichprobe weiblich, die zweite Stichprobe männlich)</description>
    </item>
    
    <item>
      <title>unabhängige Variable</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/unabhaengigevariable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/unabhaengigevariable/</guid>
      <description>Die unabhängige Variable (Kurzform: uV) ist die Variable, die die Wirkung auslöst (Ursache). Sie wird zumeist mit X bezeichnet. Sie kann auch als Prädiktor-Variable oder erklärende Variable bezeichnet.</description>
    </item>
    
    <item>
      <title>Variable</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/variable/</guid>
      <description>Variablen sind die gemessenen Merkmale bzw. Eigenschaften von Beobachtungseinheiten. Jede Variable bildet ein Merkmal und dessen Merkmalsausprägungen ab.</description>
    </item>
    
    <item>
      <title>Varianz</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/varianz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/varianz/</guid>
      <description>Streuungsmaß; Zeichen der Varianz \(\sigma^2\); Summe der quadrierten Abweichungen der Werte vom Mittelwert; Einheit der Varianz ist nicht interpretierbar; Berechnung: \(s^2=\sigma^2=\frac{1}{n} \ast \sum_{i=1}^n(x_i - \bar{x})^2\) Für die Berechnung einer Standardabweichung aus einer Stichprobe wird die Bessel-Korrektur angewendet (\(\frac{1}{n-1}\)):
\[s^2 = \frac{1}{n-1}* \sum_{i=1}^n (x_i - \bar{x})^2\]</description>
    </item>
    
    <item>
      <title>Vertrauenswahrscheinlichkeit</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/vertrauenswahrscheinlichkeit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/vertrauenswahrscheinlichkeit/</guid>
      <description>gibt die Wahrscheinlichkeit an, dass ein Intervall den wahren Wert enthält (\(p=1- \alpha\))</description>
    </item>
    
    <item>
      <title>Willkürliche Auswahl</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/willkuerlicheauswahl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/willkuerlicheauswahl/</guid>
      <description>Verfahren der nicht-wahrscheinlichkeitsbasierten Auswahl einer Stichprobe; Auswahl auf das Geratewohl (willkürliche Entscheidung); Grundgesamtheit ist nicht identifizierbar; Beispiel Schneeball-Auswahl.</description>
    </item>
    
    <item>
      <title>z-Verteilung</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/zverteilung/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/zverteilung/</guid>
      <description>auch Standardnormalverteilung genannt; Transformierte Form der Normalverteilung; für eine Standardnormalverteilung gilt: \(\bar{x}=0, s^2=s =1\) ; z-Transformation: \(z_i = \frac{x_i - \bar{x}}{s}\) ; z-Wert geben relative Position des Rohwertes zum Mittelwert in Standardabweichungen an.</description>
    </item>
    
    <item>
      <title>Zufallsstichprobe</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/zufallsstichprobe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/zufallsstichprobe/</guid>
      <description>Verfahren der Stichprobenziehung, dass auf der Stochastik beruht; mithilfe von Zufallsstichproben können Verfahren der Inferenzstatistik angewendet werden.</description>
    </item>
    
    <item>
      <title>zweiseitiger Signifikanztest</title>
      <link>https://lehre.bpkleer.de/stats101/LM4/glossar/zweiseitigertest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lehre.bpkleer.de/stats101/LM4/glossar/zweiseitigertest/</guid>
      <description>uch Hypothesentest, auch ungerichteter S.; es wird keine Richtung festgelegt; der Ablehnungsbereich einer Hypothese ist je hälftig auf beiden Seiten anzulegen \((\frac {\alpha} {2} \thinspace und \thinspace (1-\frac {\alpha} {2}))\)</description>
    </item>
    
  </channel>
</rss>
