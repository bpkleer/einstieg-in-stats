---
title: "Anwendung Korrelation"
weight: 105
tags: ["praxis", "signifikanz", "hypothesentest"]
bibliography: [../../static/files/publications.bib]
suppress-bibliography: true
link-citations: true
# nocite: "@*" um einfach alle Angaben zu printen am Ende
csl: [../../static/files/apa.csl]
---

{{% buttonGit href=\"https\:\/\/gitlab.ub.uni-giessen.de\/methoden-politik\/einstieg-in-statistik\/issues\/new?issue[title]=\" icon=\"fas fa-bug\" %}} {{% /buttonGit %}} 

{{% buttonGit href=\"https\:\/\/twitter.com\/share?url=\" icon=\"fab fa-twitter\" %}} {{% /buttonGit %}}

{{% buttonGit href=\"https\:\/\/www.facebook.com\/sharer\/sharer.php?u=\" icon=\"fab fa-facebook\" %}} {{% /buttonGit %}}

Auch bei [Korrelationen](../../glossar/korrelation/index.html) testet man die **Signifikanz.** Es wird also geprüft, ob der Zusammenhang in der [Grundgesamtheit](../../glossar/grundgesamtheit/index.html) auch wahrscheinlich ist. In unserem vorherigen Teil haben wir die Ergebnisse noch nicht auf **Signifikanz** geprüft. Daher werden wir dies nun im Beispiel berechnen und durchführen.

Zur Erinnerung unser Beispiel aus der Berechnung der [Pearson-Korrelation](../../glossar/pearsonsr/index.html): Wir haben eine Stichprobe mit $5$ Fällen, die jeweils das *Alter* und die *Präferenz zur Partei CDU* angegeben haben. Dies ist ein fiktives Beispiel, dass auf keiner [Zufallsstichprobe](../../glossar/zufallsstichprobe/index.html) basiert. Für die Einfachheit des Rechenbeispiels wird aber hier angenommen, dass es sich um eine ausreichend große Zufallsstichprobe für die Berechnung der Signifikanz handelt.

| Fall(i) | Alter ($x_i$) | Wahlpräferenz CDU ($y_i$) |
|:-------:|:-------:|:-------:|
| 1 | 19 | 24 |
| 2 | 24 | 41 |
| 3 | 27 | 20 |
| 4 | 56 | 74 |
| 5 | 69 | 81 |

Für diese zwei [Variablen](../../glossar/variable/index.html) haben wir die [Pearson-Korrelation](../../glossar/pearsonsr/index.html) (hier) berechnet, die folgenden Wert ergab:
$r \approx 0.97$

Für den **Signifikanztest** stellen wir nun eine [Null-](../../glossar/nullhypothese/index.html) und [Alternativhypothese](../../glossar/alternativhypothese/index.html) auf.

Die Nullhypothese des **Signifikanztests** lautet bei einer Korrelation immer:
$H_0: r = 0$

Die Alternativhypothese ist in der Regel ungerichtet. Es wird also keine konkrete Hypothese über die Höhe der Korrelation geprüft, sondern es wird nur die Signifikanz des Zusammenhangs geprüft.

Die Alternativhypothese lautet daher:
$H_A: r \neq 0$

Als [Irrtumswahrscheinlichkeit](../../glossar/irrtumswahrscheinlichkeit/index.html) nehmen wir den Standardwert von $\alpha = 0.05 (\Rightarrow p = 1 - \frac{\alpha}{2} = 0.975)$ (zweiseitiger Test!).

Im Fall der Korrelation wird die Signifikanz mithilfe einer bestimmten Verteilung getestet. Dafür wird eine Prüfgröße errechnet, die dann mit dem [kritischen Wert](../../glossar/kritischerwert/index.html) einer Verteilung verglichen wird. Wenn die Prüfgröße größer als der kritische Wert ist, gilt das Ergebnis als signifikant. Für große Stichproben ($n>100$) kann eine [Normalverteilung](../../glossar/normalverteilung/index.html) der Prüfgröße angenommen werden, ansonsten muss eine [t-Verteilung](../../glossar/tverteilung/index.html) angenommen werden.

<br>

## Berechnung

Um bewerten zu können, ob unser Ergebnis signifikant ist, müssen wir folgendes berücksichtigen:
[Stichprobengröße](../../glossar/stichprobenumfang/index.html): $n=5$
[Korrelationskoeffizient](../../glossar/korrelation/index.html): $r=0.97$

Da die Stichprobe ($n=5$) klein ist, wird eine $t$-Verteilung für die Verteilung der Prüfgröße angenommen. In einigen Fällen wird die Prüfgröße dann auch $t$−Wert genannt. Mathematisch wird dies meist mit $t_{emp}$ oder $t_{krit}$ angegeben.

Die Prüfgröße des Korrelationsergebnisses berechnet sich nach folgender Formel:

$t_{emp} = \frac {|r|}{\sqrt\frac{1-r^2}{N-2}} = |r| \ast \sqrt \frac{N-2}{1-r^2}$

Zur Erinnerung hier nochmal unsere Daten:

$r \approx 0.97$

$N=5$

Setzen wir unseren Daten nun in die Formel ein:

$t_{emp} = \frac {0.97} {\sqrt \frac{1 - 0.97^2}{5-2}} \approx \frac {0.97} {0.1404} \approx 6,909$

Unsere errechnete Prüfgröße ist also $t_{emp} \approx 6.909$.

Nun muss diese errechnete Prüfgröße mit dem kritischen Wert abgeglichen werden. Ist die Prüfgröße größer als der kritische Wert, gilt das Ergebnis als signifikant.

Den kritischen Wert liest man anhand von Verteilungstabellen aus. Dazu benötigt man die angegebene Irrtumswahrscheinlichkeit (hier: $1-\alpha=0.95$) und die Freiheitsgrade (*degree of freedom*).

Die Freiheitsgerade ($\nu$) errechnen sich wie folgt:

$\nu=n−1$

Im Beispiel also:

$\nu=5−1=4$

In einer [t-Verteilungs-Tabelle](../../glossar/tverteilung/index.html) liest man den entsprechenden kritischen Wert aus. Hier ein Ausschnitt der Tabelle:

![t-Verteilungs-Tabelle](../images/tverteilung.png)

Der kritische Wert beträgt an der genannten Stelle:
$t_{krit_{(\nu=4;p=0.975)}} = 2.776$.

Damit das errechnete Ergebnis der Signifikanz gilt, muss:
$t_{emp} > t_{krit}$

Im Beispiel ist dies erfüllt: $6.909 > 2.776$

Unsere Prüfgröße ist größer als der kritische Wert und damit können wir die Nullhypothese ablehnen. Somit läge in diesem Beispiel ein gesicherter statistischer Zusammenhang zwischen den zwei Merkmalen vor. Wir könnten also das Ergebnis der Stichprobe auf die Grundgesamtheit übertragen. Voraussetzung dafür wäre aber, dass die Stichprobe zufallsbasiert erfolgt wäre.

<br>

## Interpretationsfehler

Bei der Interpretation der **Signifikanz** sollten folgende Fehlinterpretationen allerdings vermieden werden (Schnell et al. 2013, S. 442):

Ein signifikantes Ergebnis bedeutet nicht, dass …

- es sich um einen „wichtigen“ Effekt handelt,

- die „Existenz“ eines Effekts bewiesen ist,

- es sich um einen „starken“ Effekt handelt.

Ob ein Effekt theoretisch wichtig oder nicht ist, kann nicht durch ein mathematisches Verfahren bestimmt werden. Des Weiteren prüfen wir die Signifikanz immer unter einer [Irrtumswahrscheinlichkeit](../../glossar/irrtumswahrscheinlichkeit/index.html), die in aller Regel dem $5\%$-[Signifikanzniveau](../../glossar/signifikanzniveau/index.html) entspricht. Dies bedeutet, dass wir in $5\%$ der Fälle einen nicht vorhandenen Effekt als signifikant einstufen. Die Existenz kann daher nicht bewiesen werden, da der **Signifikanztest** nicht zwischen tatsächlichen Effekt oder zufälligen Fehler bestimmen kann.

Wir können nur die Aussage treffen, dass wenn ein Wert **signifikant** ist, dieser bei wiederholten unabhängigen Untersuchungen sehr wahrscheinlich ist. Die Stärke des Effekts wird ebenfalls nicht durch die **Signifikanz** angegeben, sondern durch die Höhe des auf **Signifikanz** geprüften Wertes. Ein **signifikanter** Wert kann sehr klein, mittel oder sehr stark sein. Die **Signifikanz** allein lässt keine Aussage über die Stärke eines Effekts zu.

{{% notice tip %}}
Siehe auch: @Bortz2005 [Kapitel 4.4]; @Schnell2013 [Kapitel 9.4].
{{% /notice %}}