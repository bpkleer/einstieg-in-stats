---
title: "Regressionskoeffizienten"
weight: 313
tags: ["regressionskoeffizienten", "regression"]
bibliography: [../../../static/files/publications.bib]
suppress-bibliography: true
link-citations: true
# nocite: "@*" um einfach alle Angaben zu printen am Ende
csl: [../../../static/files/apa.csl]
---

{{% buttonGit href=\"https\:\/\/gitlab.ub.uni-giessen.de\/methoden-politik\/einstieg-in-statistik\/issues\/new?issue[title]=\" icon=\"fas fa-bug\" %}} {{% /buttonGit %}} 

{{% buttonGit href=\"https\:\/\/twitter.com\/share?url=\" icon=\"fab fa-twitter\" %}} {{% /buttonGit %}}

{{% buttonGit href=\"https\:\/\/www.facebook.com\/sharer\/sharer.php?u=\" icon=\"fab fa-facebook\" %}} {{% /buttonGit %}}

In Veröffentlichungen von Regressionsmodellen finden Sie neben der Angabe des [Bestimmtheitsmaßes $R^2$](../../../glossar/bestimmtheitsmass/index.html) auch immer die Angabe der einzelnen **Regressionskoeffizienten** und deren **Signifikanz**. Denn in den meisten Regressionsmodellen geht es nicht nur um die Erklärungskraft eines Modells, sondern auch darum, wie einzelne Faktoren auf die abhängige [Variable](../../../glossar/variable/index.html) wirken. Daher ist die Angabe und die Interpretation der **Regressionskoeffizienten** wichtig.

In der Abbildung sehen wir wieder einen Auszug der Beispielregression: Im Computerprogramm SPSS wird dieser als Koeffizientenblock bezeichnet, in R finden wir diese auch wie zuvor in der normalen Modell-Ausgabe.

![Koeffizientenblock Regression (SPSS)](../images/spss-multi-coef.png)

![Modell lineare Regression unstandardisierte Regressionskoeffizienten (R)](../images/r-reg-multi.PNG)

![Modell lineare Regression standardisierte Regressionskoeffizienten (R)](../images/r-reg-multi-z.PNG)

Generell unterscheiden wir zwischen **standardisierten** und **nicht-standardisierten Regressionskoeffizienten**. In SPSS werden beide direkt ausgegeben, in R die unstandardisierten (sofern man nicht vorher die Variablen standardisiert). In dem man die Variablen standardisiert und die Regression erneut berechnet (untere R-Tabelle) oder spezielle Funktionen anwendet, erhält man auch in R die standardisierten Regressionskoeffizienten. In Veröffentlichungen werden meist entweder die **standardisierten** oder die **nicht-standardisierten Regressionskoeffizienten** angegeben.

**Nicht-standardisiert** bedeutet, dass die **Regressionskoeffizienten** in der Maßeinheit der Variable ausgegeben werden. In unserem Beispiel werden daher die **nicht-standardisierten Regressionskoeffizienten** wie folgt interpretiert: Mit einer Steigerung um eine Einheit auf der Variable *Zufriedenheit mit der ökonomischen Leistung* (Einheit ist ein Jahr), steigt die *Zufriedenheit mit der Demokratie* um $0.544$ Punkte. Mit einer Steigerung um eine Einheit auf der Variable *Einkommen* ($1$ Euro) steigt die *Zufriedenheit mit der Demokratie* um $0.001$ Punkte.

Doch welche Variable ist nun einflussreicher? Mithilfe der **nicht-standardisierten Regressionskoeffizienten** kann diese Frage nicht beantwortet werden, da die Wirkung auf die abhängige Variable in unterschiedlichen Einheiten angegeben ist. Zum Vergleich der Stärke der Koeffizienten innerhalb des Modells eignen sich **nicht-standardisierte Regressionskoeffizienten** also nicht.

**Standardisierte Regressionskoeffizienten** sind über die [Standardabweichung](../../../glossar/standardabweichung/index.html) (z-Transformation: $\beta_k = b_k\ast \frac {s_{x_k}} {s_y}$) von der Maßeinheit der Variablen losgelöst. Die Maßeinheit der **standardisierten Regressionskoeffizienten** ist die Standardabweichung. Damit kann die unterschiedliche Stärke des Einflusses der Koeffizienten innerhalb eines Modells verglichen werden.

Interpretativ sagt dieser Wert dann aus, um wie viel Standardabweichungen sich die abhängige Variable bei Erhöhen um eine Standardabweichung der [unabhängigen Variable](../../../glossar/unabhaengigevariable/index.html) ändert. Der Wertebereich reicht in aller Regel von $[-1;1]$. Ein Wert von $-1$ ist dabei als perfekt inverse Beziehung zu deuten ($y$ sinkt um eine Standardabweichung, wenn x um eine Standardabweichung steigt) und bei $+1$ als *perfekt positiver Zusammenhang*. Werte von größer $1$ oder kleiner $−1$ bei standardisierten Regressionskoeffizienten weisen auf Multikollinearität (Variablen korrelieren untereinander zu stark) zwischen Variablen hin.

Im Beispiel von oben steigt die *Zufriedenheit mit der Demokratie* um $0.607$ Standardabweichungen, wenn die *Zufriedenheit mit der ökonomischen Leistung* um eine Standardabweichung erhöht wird. Die *Zufriedenheit mit der Demokratie* steigt dagegen um $0.385$ Standardabweichungen, wenn das *Einkommen* um eine Standardabweichung steigt. Der Effekt der *Zufriedenheit mit der ökonomischen Leistung* ist damit größer als der Effekt des *Einkommens.*

Vorsicht ist geboten bei modellübergreifender Interpretation. Die **standardisierten Regressionskoeffizienten** lassen sich nämlich nur innerhalb eines Modells vergleichen, da diese über die Varianz berechnet werden und in zwei unterschiedlichen Stichproben können die Varianzen differieren. Es würde sich daher für dieselbe Rechnung unterschiedliche **standardisierte Regressionskoeffizienten** ergeben.

| Regressionskoeffizient | Maßeinheit | Interpretation |
|:--------:|:-----:|:--------:|
| unstandardisiert | Einheit der jeweiligen Variablen | kein Vergleich der unabhängigen Variablen im selben Modell möglich; Interpretation leichter, da in Maßeinheit der Variablen
| standardisiert | Standardabweichung  | relative Stärke zwischen unabhängigen Variablen im selben Modell vergleichbar | 

Die **Regressionskoeffizienten** werden jeweils auch auf [Signifikanz](../../../glossar/signifikanztest/index.html) über einen [t-Test](../../../glossar/ttestregression/index.html) geprüft. Zur Wiederholung: Es wird also überprüft, ob der angegebene Wert in der Stichprobe auf den Wert der [Grundgesamtheit](../../../glossar/grundgesamtheit/index.html) übertragen werden kann. Hieraus ergibt sich forschungspraktisch, welche **Regressionskoeffizienten** interpretierbar sind, da die signifikanten **Regressionskoeffizienten** Bedeutung über die Stichprobe hinaus haben. In den meisten Veröffentlichungen wird dies mit Sternen ($\star$, $\star \star$, $\star \star \star$) markiert. Welche Sterne für welches [Signifikanzniveau](../../../glossar/signifikanzniveau/index.html) gelten, ist unterschiedlich und ist immer unterhalb einer Regressionstabelle angegeben. Üblich ist folgende Konvention:

| Zeichen | Signifikanzniveau |
|:--------:|:-----:|
| $\dag$ | 0.10 |
| <sup>*</sup> | 0.05  |
| <sup>**</sup> | 0.01 |
| <sup>***</sup> | 0.001  |

Im Beispiel von oben befinden sich der t-Wert jedes einzelnen **Regressionskoeffizienten** in der Spalte t-Wert und die Signifikanz entsprechend in der Spalte Sig (SPSS-Ausgabe). Sowohl für die Zufriedenheit mit der ökonomischen Leistung als auch das Einkommen ist die Signifikanz gegeben ($p$-Wert unter kritischer Grenze von $0,05$).

In der Ausgabe von R sehen wir im Block Coefficients: in der vorletzten Spalte den $t$-Wert und in der letzten Wahrscheinlichkeit die Signifikanz. Auch hier zeigt sich, dass beide Variablen einen signifikanten Einfluss haben.

{{% notice tip %}}
Siehe auch: @Urban2011 [Kapitel 3.4.1].
{{% /notice %}}